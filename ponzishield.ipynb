{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9300,"status":"ok","timestamp":1703937797159,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"-LRJWLGYwu6g"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import RobertaModel, RobertaTokenizer\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","from torch.nn.functional import normalize\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","from torch.optim.lr_scheduler import ExponentialLR\n","from sklearn.model_selection import train_test_split\n","import os"]},{"cell_type":"markdown","metadata":{"id":"Tk2fqEluw4dy"},"source":["----------------------------------------------------------\n","To fix the error `Torch compile: libcuda.so cannot found` raised by\n","```python\n","torch.compile(robertaModel, backend=\"inductor\")\n","```\n","----------------------------------------------------------"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3289,"status":"ok","timestamp":1703937803425,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"EO54NZ3dw67y","outputId":"8ce27467-8b00-4826-cd04-1e371de9af23"},"outputs":[{"name":"stdout","output_type":"stream","text":["/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n"]}],"source":["!export LC_ALL=\"en_US.UTF-8\"\n","!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n","!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n","!ldconfig /usr/lib64-nvidia"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":495,"status":"ok","timestamp":1703939210914,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"Dwhp4wcJw8TE","outputId":"720ced18-e88a-41e9-a69a-83c7c30d718b"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["# Check for GPU availability\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"R1D53VQ5AaYm"},"source":["#### Social Media Modality"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":597,"status":"ok","timestamp":1703937807081,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"ybafLp41xB9H"},"outputs":[],"source":["class SocialMedia(nn.Module):\n","    def __init__(\n","        self,\n","        device,\n","        roberta_model_path='roberta-base',\n","        num_classes=1,\n","        inductor=True,\n","        independent=True,\n","        embedding_dir='/content/drive/Shareddrives/test/FYP/socialmedia/embedding_files'\n","        ):\n","        super(SocialMedia, self).__init__()\n","\n","        self.independent = independent\n","        self.embedding_dir = embedding_dir\n","        os.makedirs(self.embedding_dir, exist_ok=True)\n","\n","        # Load pre-trained RoBERTa model\n","        self.roberta = RobertaModel.from_pretrained(roberta_model_path).to(device=device)\n","        if (inductor):\n","          self.roberta = torch.compile(self.roberta, backend=\"inductor\")\n","        self.tokenizer = RobertaTokenizer.from_pretrained(roberta_model_path)\n","\n","        # CNN\n","        self.conv1d_p1 = nn.Conv1d(in_channels=768, out_channels=128, kernel_size=5).to(device=device)\n","        self.conv1d_p2 = nn.Conv1d(in_channels=768, out_channels=128, kernel_size=4).to(device=device)\n","        self.conv1d_p3 = nn.Conv1d(in_channels=768, out_channels=128, kernel_size=3).to(device=device)\n","        self.conv1d_s1 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5).to(device=device)\n","        self.conv1d_s2 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5).to(device=device)\n","\n","        # Pooling\n","        self.max_pool_p1 = nn.MaxPool1d(kernel_size=5).to(device=device)\n","        self.max_pool_p2 = nn.MaxPool1d(kernel_size=5).to(device=device)\n","        self.max_pool_p3 = nn.MaxPool1d(kernel_size=5).to(device=device)\n","        self.max_pool_s1 = nn.MaxPool1d(kernel_size=5).to(device=device)\n","        self.max_pool_s2 = nn.MaxPool1d(kernel_size=10).to(device=device)\n","\n","        # Fully connected layers\n","        self.linear1 = nn.Linear(640, 128).to(device=device)\n","        self.linear2 = nn.Linear(128, num_classes).to(device=device)\n","        self.sigmoid = nn.Sigmoid().to(device=device)\n","\n","    def forward(self, x, iteration, train, mode):\n","        # If the module is independent it self will create embeddings\n","        if (self.independent):\n","            # Check if embeddings are already saved to disk\n","            embedding_path = os.path.join(self.embedding_dir, f'{mode}_{iteration}.pth')\n","            if (train and os.path.exists(embedding_path)):\n","                # Load embeddings from disk\n","                # print('using saved embeddings')\n","                try:\n","                    embeddings = torch.load(embedding_path).to(device=device)\n","                except Exception as e:\n","                    print('Error loading embeddings:', e)\n","            else:\n","                # Tokenize and encode the sentences\n","                tokenized_sentences = self.tokenizer(x, truncation=True, padding='max_length', return_tensors='pt').to(device=device)\n","\n","                # Forward pass to get embeddings\n","                with torch.no_grad():\n","                    # Get RoBERTa embeddings\n","                    model_output = self.roberta(**tokenized_sentences)\n","\n","                # Extract embeddings from the output\n","                embeddings = model_output.last_hidden_state\n","\n","                # Save embeddings to disk\n","                torch.save(embeddings.cpu(), embedding_path)\n","        else:\n","            embeddings = x\n","\n","        output_p1 = self.max_pool_p1(F.relu(self.conv1d_p1(embeddings.permute(0, 2, 1))))\n","        output_p2 = self.max_pool_p2(F.relu(self.conv1d_p2(embeddings.permute(0, 2, 1))))\n","        output_p3 = self.max_pool_p3(F.relu(self.conv1d_p3(embeddings.permute(0, 2, 1))))\n","        output_s = torch.cat((output_p1, output_p2, output_p3), dim=2)\n","        output_s1 = F.relu(self.conv1d_s1(output_s))\n","        output_s1 = self.max_pool_s1(output_s1)\n","        output_s2 = F.relu(self.conv1d_s2(output_s1))\n","        output_s2 = self.max_pool_s2(output_s2)\n","        output_s2 = output_s2.permute(0, 2, 1)\n","        output_f = output_s2.reshape(output_s2.size(0), -1)\n","        output_l1 = torch.relu(self.linear1(output_f))\n","        output_l2 = self.linear2(output_l1)\n","        output = self.sigmoid(output_l2)\n","\n","        # Release memory\n","        del embeddings\n","\n","        return output, output_l1"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1703937810300,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"DdcgjLCVxXal"},"outputs":[],"source":["class TFN(nn.Module):\n","    def __init__(\n","        self,\n","        device,\n","        inductor=True,\n","        roberta_model_path='roberta-base',\n","        socialmedia_out=128,\n","        post_fusion_dim=256,\n","        post_fusion_dropout=0,\n","        embedding_dir='/content/drive/Shareddrives/test/FYP/socialmedia/embedding_files'\n","        ):\n","        super(TFN, self).__init__()\n","\n","        self.embedding_dir = embedding_dir\n","        os.makedirs(self.embedding_dir, exist_ok=True)\n","\n","        self.socialmedia_out = socialmedia_out\n","        self.post_fusion_dim = post_fusion_dim\n","        self.post_fusion_dropout = nn.Dropout(p=post_fusion_dropout).to(device=device)\n","\n","        # Load pre-trained RoBERTa model\n","        self.roberta = RobertaModel.from_pretrained(roberta_model_path).to(device=device)\n","        if (inductor):\n","          self.roberta = torch.compile(self.roberta, backend=\"inductor\")\n","        self.tokenizer = RobertaTokenizer.from_pretrained(roberta_model_path)\n","\n","        # Load pre-trained FakeBERT models\n","        self.sentiment = SocialMedia(device=device, inductor=inductor, independent=False)\n","        self.sentiment.load_state_dict(torch.load('/content/drive/Shareddrives/test/FYP/sentiment/sentiment-usairline.pth'))\n","\n","        self.fakenews = SocialMedia(device=device, inductor=inductor, independent=False)\n","        self.fakenews.load_state_dict(torch.load('/content/drive/Shareddrives/test/FYP/fake-news/fakenews.pth'))\n","\n","        # define the post_fusion layers\n","        self.post_fusion_layer_1 = nn.Linear((self.socialmedia_out) * (self.socialmedia_out), self.post_fusion_dim).to(device=device)\n","        self.post_fusion_layer_2 = nn.Linear(self.post_fusion_dim, self.post_fusion_dim).to(device=device)\n","\n","    def fetchFromReddit(self, dapp_address):\n","        # TODO: Retrieve 10 posts for dapp from reddit\n","        return [\"I love this product!\"]*10\n","\n","\n","    def forward(self, dapp_address, iteration, train, mode):\n","        # Check if embeddings are already saved to disk\n","        embedding_path = os.path.join(self.embedding_dir, f'{mode}_{dapp_address}.pth')\n","\n","        if (train and os.path.exists(embedding_path)):\n","            # Load embeddings from disk\n","            print('using saved embeddings')\n","            try:\n","                embeddings = torch.load(embedding_path).to(device=device)\n","            except Exception as e:\n","                print('Error loading embeddings:', e)\n","        else:\n","            # Get posts from reddit\n","            sentences = self.fetchFromReddit(dapp_address)\n","\n","            # Tokenize and encode the sentences\n","            tokenized_sentences = self.tokenizer(sentences, truncation=True, padding='max_length', return_tensors='pt').to(device=device)\n","\n","            # Forward pass to get embeddings\n","            with torch.no_grad():\n","                # Get RoBERTa embeddings\n","                model_output = self.roberta(**tokenized_sentences)\n","\n","            # Extract embeddings from the output\n","            embeddings = model_output.last_hidden_state\n","\n","            # Save embeddings to disk\n","            torch.save(embeddings.cpu(), embedding_path)\n","\n","        sentiment, sentiment_h = self.sentiment(embeddings, iteration, train, mode)\n","        # print('sentiment_h', sentiment_h.shape)\n","        fakenews, fakenews_h = self.fakenews(embeddings, iteration, train, mode)\n","        # print('fakenews_h', fakenews_h.shape)\n","\n","        # sentiment_h has shape (batch_size, self.socialmedia_out), _video_h has shape (batch_size, self.socialmedia_out)\n","        # we want to perform outer product between the two batch, hence we unsqueenze them to get\n","        # (batch_size, self.socialmedia_out, 1) X (batch_size, 1, self.socialmedia_out)\n","        # fusion_tensor will have shape (batch_size, self.socialmedia_out, self.socialmedia_out)\n","        fusion_tensor = torch.bmm(sentiment_h.unsqueeze(2), fakenews_h.unsqueeze(1))\n","        # print('fusion_tensor', fusion_tensor.shape)\n","\n","        batch_size = sentiment_h.shape[0]\n","        fusion_tensor = fusion_tensor.view(batch_size, -1)\n","        # print('fusion_tensor', fusion_tensor.shape)\n","\n","        post_fusion_dropped = self.post_fusion_dropout(fusion_tensor)\n","        # print('post_fusion_dropped', post_fusion_dropped.shape)\n","        post_fusion_y_1 = F.relu(self.post_fusion_layer_1(post_fusion_dropped))\n","        # print('post_fusion_y_1', post_fusion_y_1.shape)\n","        post_fusion_y_2 = F.relu(self.post_fusion_layer_2(post_fusion_y_1))\n","        # print('post_fusion_y_2', post_fusion_y_2.shape)\n","        output = post_fusion_y_2\n","\n","        # Release memory\n","        del embeddings\n","\n","        return output\n"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1703938509260,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"ZCrSLgehFKJq"},"outputs":[],"source":["class SocialMediaModality(nn.Module):\n","    def __init__(\n","        self,\n","        device,\n","        inductor=True,\n","        roberta_model_path='roberta-base',\n","        socialmedia_out=128,\n","        post_fusion_dim=256,\n","        post_fusion_dropout=0,\n","        embedding_dir='/content/drive/Shareddrives/test/FYP/socialmedia/embedding_files'\n","        ):\n","        super(SocialMediaModality, self).__init__()\n","\n","        self.tfn = TFN(\n","            device,\n","            inductor,\n","            roberta_model_path,\n","            socialmedia_out,\n","            post_fusion_dim,\n","            post_fusion_dropout,\n","            embedding_dir\n","        )\n","\n","    def forward(self, dapp_addresses, iteration, train, mode):\n","        # List to store individual outputs for each address\n","        outputs_list = []\n","\n","        # Iterate through dapp_addresses\n","        for dapp_address in dapp_addresses:\n","            # Get posts from reddit\n","\n","            outputs = self.tfn(dapp_address, iteration, train, mode)\n","\n","            # Append the outputs to the list\n","            outputs_list.append(outputs)\n","\n","        # Combine the outputs into a single tensor\n","        combined_outputs = torch.stack(outputs_list, dim=0).to(device=device)\n","\n","        return combined_outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48647,"status":"ok","timestamp":1703879001441,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"SxSTHX1xZDvT","outputId":"8362e5c9-44dd-466e-95c4-791e1e3cbc72"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["torch.Size([10, 256])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize the model\n","tfn = TFN(\n","    device,\n","    inductor=True\n",")\n","\n","sentences = [\"I love this product!\"]*10\n","\n","outputs = tfn(sentences, 1, False, 'test')\n","outputs.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14549,"status":"ok","timestamp":1703879024650,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"3Z7ZF8qoq-at","outputId":"3e69a53a-0aaf-4df4-d97d-5b03109c4465"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["torch.Size([20, 10, 256])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize the model\n","socialMediaModality = SocialMediaModality(\n","    device,\n","    inductor=True\n",")\n","\n","addresses_tensor = torch.randint(1000, 10000, size=(20, 1), dtype=torch.int32)\n","\n","output = socialMediaModality(addresses_tensor, 1, True, 'train')\n","\n","output.shape"]},{"cell_type":"markdown","metadata":{"id":"CWNnsoKsAUlx"},"source":["#### Multi-Modal Fusion"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":482,"status":"ok","timestamp":1703937836921,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"RxpXgGz4AfnN"},"outputs":[],"source":["'''\n","Sample-Weighted Focal Contrastive (SWFC) Loss:\n","1. Divide training samples into positive and negative pairs to maximize\n","inter-class distances while minimizing intra-class distances;\n","2. Assign more importance to hard-to-classify positive pairs;\n","3. Assign more importance to minority classes.\n","'''\n","class SampleWeightedFocalContrastiveLoss(nn.Module):\n","\n","    def __init__(self, temp_param, focus_param, sample_weight_param, dataset, class_counts, device):\n","        '''\n","        temp_param: control the strength of penalty on hard negative samples;\n","        focus_param: forces the model to concentrate on hard-to-classify samples;\n","        sample_weight_param: control the strength of penalty on minority classes;\n","        dataset: MELD or IEMOCAP.\n","        device: cpu or cuda.\n","        '''\n","        super().__init__()\n","\n","        self.temp_param = temp_param\n","        self.focus_param = focus_param\n","        self.sample_weight_param = sample_weight_param\n","        self.dataset = dataset\n","        self.class_counts = class_counts\n","        self.device = device\n","\n","        if self.dataset == 'MELD':\n","            self.num_classes = 7\n","        elif self.dataset == 'IEMOCAP':\n","            self.num_classes = 6\n","        else:\n","            raise ValueError('Please choose either MELD or IEMOCAP')\n","\n","        self.class_weights = self.get_sample_weights()\n","\n","\n","    '''\n","    Use dot-product to measure the similarity between feature pairs.\n","    '''\n","    def dot_product_similarity(self, current_features, feature_sets):\n","        similarity = torch.sum(current_features * feature_sets, dim = -1)\n","        similarity_probs = torch.softmax(similarity / self.temp_param, dim = 0)\n","\n","        return similarity_probs\n","\n","\n","    '''\n","    Calculate the loss contributed from positive pairs.\n","    '''\n","    def positive_pairs_loss(self, similarity_probs):\n","        pos_pairs_loss = torch.mean(torch.log(similarity_probs) * ((1 - similarity_probs)**self.focus_param), dim = 0)\n","\n","        return pos_pairs_loss\n","\n","\n","    '''\n","    Assign more importance to minority classes.\n","    '''\n","    def get_sample_weights(self):\n","        total_counts = torch.sum(self.class_counts, dim = -1)\n","        class_weights = (total_counts / self.class_counts)**self.sample_weight_param\n","        class_weights = normalize(class_weights, dim = -1, p = 1.0)\n","\n","        return class_weights\n","\n","\n","    def forward(self, features, labels):\n","        self.num_samples = labels.shape[0]\n","        self.feature_dim = features.shape[-1]\n","\n","        features = normalize(features, dim = -1)  # normalization helps smooth the learning process\n","\n","        batch_sample_weights = torch.FloatTensor([self.class_weights[label] for label in labels]).to(self.device)\n","\n","        total_loss = 0.0\n","        for i in range(self.num_samples):\n","            current_feature = features[i]\n","            current_label = labels[i]\n","            feature_sets = torch.cat((features[:i], features[i + 1:]), dim = 0)\n","            label_sets = torch.cat((labels[:i], labels[i + 1:]), dim = 0)\n","            expand_current_features = current_feature.expand(self.num_samples - 1, self.feature_dim).to(self.device)\n","            similarity_probs = self.dot_product_similarity(expand_current_features, feature_sets)\n","            pos_similarity_probs = similarity_probs[label_sets == current_label]  # positive pairs with the same label\n","            if len(pos_similarity_probs) > 0:\n","                pos_pairs_loss = self.positive_pairs_loss(pos_similarity_probs)\n","                weighted_pos_pairs_loss = pos_pairs_loss * batch_sample_weights[i]\n","                total_loss += weighted_pos_pairs_loss\n","\n","        loss = - total_loss / self.num_samples\n","\n","        return loss"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1703937837408,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"LArJF67ZAjoF"},"outputs":[],"source":["'''\n","Maximize the correlations across multimodal-fused features\n","extracted from MultiAttn through Soft-HGR loss.\n","'''\n","class SoftHGRLoss(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","\n","    '''\n","    Calculate the inner products between feature mappings.\n","    '''\n","    def feature_mapping(self, feature_X, feature_Y):\n","        feature_mapping_X_Y = torch.mean(torch.sum(feature_X * feature_Y, dim = -1), dim = 0)\n","\n","        return feature_mapping_X_Y\n","\n","\n","    '''\n","    Calculate the inner products between feature covariances.\n","    '''\n","    def feature_covariance(self, feature_X, feature_Y):\n","        cov_feature_X = torch.cov(feature_X)\n","        cov_feature_Y = torch.cov(feature_Y)\n","        # We empirically find that scaling the feature covariance by a factor of 1 / num_samples\n","        # leads to enhanced training stability and improvements in model performances.\n","        feature_covariance_X_Y = torch.trace(torch.matmul(cov_feature_X, cov_feature_Y)) / self.num_samples\n","        return feature_covariance_X_Y\n","\n","\n","    def forward(self, f_t, f_a, f_v):\n","        self.num_samples = f_t.shape[0]\n","\n","        all_features = [f_t, f_a, f_v]\n","        total_loss = 0.0\n","        for i in range(len(all_features) - 1):\n","            for j in range(i + 1, len(all_features)):\n","                feature_mapping_i_j = self.feature_mapping(all_features[i], all_features[j])\n","                feature_covariance_i_j = self.feature_covariance(all_features[i], all_features[j])\n","                soft_hgr_loss_i_j = feature_mapping_i_j - feature_covariance_i_j / 2\n","                total_loss += soft_hgr_loss_i_j\n","\n","        loss = - total_loss / self.num_samples\n","\n","        return loss"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703937837408,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"2TtrSu-iAls_"},"outputs":[],"source":["'''\n","2-layer MLP with ReLU activation.\n","'''\n","class MLP(nn.Module):\n","\n","    def __init__(self, device, input_dim, hidden_dim, num_classes, dropout_rate):\n","        super().__init__()\n","\n","        self.linear_1 = nn.Linear(input_dim, hidden_dim).to(device=device)\n","        self.relu = nn.ReLU().to(device=device)\n","        self.linear_2 = nn.Linear(hidden_dim, num_classes).to(device=device)\n","        self.dropout = nn.Dropout(dropout_rate).to(device=device)\n","\n","\n","    def forward(self, x):\n","        return self.dropout(self.linear_2(self.relu(self.linear_1(x))))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1703937837408,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"i3ecQxKWAnuc"},"outputs":[],"source":["'''\n","Bidirectional cross-attention layers.\n","'''\n","class BidirectionalCrossAttention(nn.Module):\n","\n","    def __init__(self, device, model_dim, Q_dim, K_dim, V_dim):\n","        super().__init__()\n","\n","        self.query_matrix = nn.Linear(model_dim, Q_dim).to(device=device)\n","        self.key_matrix = nn.Linear(model_dim, K_dim).to(device=device)\n","        self.value_matrix = nn.Linear(model_dim, V_dim).to(device=device)\n","\n","\n","    def bidirectional_scaled_dot_product_attention(self, Q, K, V):\n","        score = torch.bmm(Q, K.transpose(-1, -2))\n","        scaled_score = score / (K.shape[-1]**0.5)\n","        attention = torch.bmm(F.softmax(scaled_score, dim = -1).to(device=device), V)\n","\n","        return attention\n","\n","\n","    def forward(self, query, key, value):\n","        Q = self.query_matrix(query)\n","        K = self.key_matrix(key)\n","        V = self.value_matrix(value)\n","        attention = self.bidirectional_scaled_dot_product_attention(Q, K, V)\n","\n","        return attention\n","\n","\n","\n","'''\n","Multi-head bidirectional cross-attention layers.\n","'''\n","class MultiHeadAttention(nn.Module):\n","\n","    def __init__(self, device, num_heads, model_dim, Q_dim, K_dim, V_dim):\n","        super().__init__()\n","\n","        self.num_heads = num_heads\n","        self.attention_heads = nn.ModuleList(\n","            [BidirectionalCrossAttention(device, model_dim, Q_dim, K_dim, V_dim) for _ in range(self.num_heads)]\n","        )\n","        self.projection_matrix = nn.Linear(num_heads * V_dim, model_dim).to(device=device)\n","\n","\n","    def forward(self, query, key, value):\n","        heads = [self.attention_heads[i](query, key, value) for i in range(self.num_heads)]\n","        multihead_attention = self.projection_matrix(torch.cat(heads, dim = -1).to(device=device))\n","\n","        return multihead_attention\n","\n","\n","\n","'''\n","A feed-forward network, which operates as a key-value memory.\n","'''\n","class Feedforward(nn.Module):\n","\n","    def __init__(self, device, model_dim, hidden_dim, dropout_rate):\n","        super().__init__()\n","\n","        self.linear_W1 = nn.Linear(model_dim, hidden_dim).to(device=device)\n","        self.linear_W2 = nn.Linear(hidden_dim, model_dim).to(device=device)\n","        self.relu = nn.ReLU().to(device=device)\n","        self.dropout = nn.Dropout(dropout_rate).to(device=device)\n","\n","\n","    def forward(self, x):\n","        return self.dropout(self.linear_W2(self.relu(self.linear_W1(x))))\n","\n","\n","\n","'''\n","Residual connection to smooth the learning process.\n","'''\n","class AddNorm(nn.Module):\n","\n","    def __init__(self, device, model_dim, dropout_rate):\n","        super().__init__()\n","\n","        self.layer_norm = nn.LayerNorm(model_dim).to(device=device)\n","        self.dropout = nn.Dropout(dropout_rate).to(device=device)\n","\n","\n","    def forward(self, x, sublayer):\n","        output = self.layer_norm(x + self.dropout(sublayer(x)))\n","\n","        return output\n","\n","\n","\n","'''\n","MultiAttn is a multimodal fusion model which aims to capture the complicated interactions and\n","dependencies across textual, audio and visual modalities through bidirectional cross-attention layers.\n","MultiAttn is made up of three sub-components:\n","1. MultiAttn_text: integrate the textual modality with audio and visual information;\n","2. MultiAttn_audio: incorporate the audio modality with textual and visual information;\n","3. MultiAttn_visual: fuse the visual modality with textual and visual cues.\n","'''\n","class MultiAttnLayer(nn.Module):\n","\n","    def __init__(self, device, num_heads, model_dim, hidden_dim, dropout_rate):\n","        super().__init__()\n","\n","        Q_dim = K_dim = V_dim = model_dim // num_heads\n","        self.attn_1 = MultiHeadAttention(device, num_heads, model_dim, Q_dim, K_dim, V_dim)\n","        self.add_norm_1 = AddNorm(device, model_dim, dropout_rate)\n","        self.attn_2 = MultiHeadAttention(device, num_heads, model_dim, Q_dim, K_dim, V_dim)\n","        self.add_norm_2 = AddNorm(device, model_dim, dropout_rate)\n","        self.ff = Feedforward(device, model_dim, hidden_dim, dropout_rate)\n","        self.add_norm_3 = AddNorm(device, model_dim, dropout_rate)\n","\n","\n","    def forward(self, query_modality, modality_A, modality_B):\n","        attn_output_1 = self.add_norm_1(query_modality, lambda query_modality: self.attn_1(query_modality, modality_A, modality_A))\n","        attn_output_2 = self.add_norm_2(attn_output_1, lambda attn_output_1: self.attn_2(attn_output_1, modality_B, modality_B))\n","        ff_output = self.add_norm_3(attn_output_2, self.ff)\n","\n","        return ff_output\n","\n","\n","\n","'''\n","Stacks of MultiAttn layers.\n","'''\n","class MultiAttn(nn.Module):\n","\n","    def __init__(self, device, num_layers, model_dim, num_heads, hidden_dim, dropout_rate):\n","        super().__init__()\n","\n","        self.multiattn_layers = nn.ModuleList([\n","            MultiAttnLayer(device, num_heads, model_dim, hidden_dim, dropout_rate) for _ in range(num_layers)])\n","\n","\n","    def forward(self, query_modality, modality_A, modality_B):\n","        for multiattn_layer in self.multiattn_layers:\n","            query_modality = multiattn_layer(query_modality, modality_A, modality_B)\n","\n","        return query_modality\n","\n","\n","\n","class MultiAttnModel(nn.Module):\n","\n","    def __init__(self, device, num_layers, model_dim, num_heads, hidden_dim, dropout_rate):\n","        super().__init__()\n","\n","        self.multiattn_text = MultiAttn(device, num_layers, model_dim, num_heads, hidden_dim, dropout_rate)\n","        self.multiattn_audio = MultiAttn(device, num_layers, model_dim, num_heads, hidden_dim, dropout_rate)\n","        self.multiattn_visual = MultiAttn(device, num_layers, model_dim, num_heads, hidden_dim, dropout_rate)\n","\n","\n","    def forward(self, text_features, audio_features, visual_features):\n","        f_t = self.multiattn_text(text_features, audio_features, visual_features)\n","        f_a = self.multiattn_audio(audio_features, text_features, visual_features)\n","        f_v = self.multiattn_visual(visual_features, text_features, audio_features)\n","\n","        return f_t, f_a, f_v"]},{"cell_type":"markdown","metadata":{"id":"bK0FGXWwA4tA"},"source":["#### Combined Model"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703940888260,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"qg2bf8K9-8RL"},"outputs":[],"source":["class PonziShield(nn.Module):\n","    def __init__(\n","        self,\n","        device,\n","        inductor=True,\n","        roberta_model_path='roberta-base',\n","        socialmedia_out=128,\n","        tensorfusion_out=256,\n","        post_fusion_dim=256,\n","        post_fusion_dropout=0,\n","        embedding_dir='/content/drive/Shareddrives/test/FYP/socialmedia/embedding_files',\n","        multi_attn_flag=True,\n","        hidden_dim=1024,\n","        dropout=0,\n","        num_layers=6,\n","        model_dim=256,\n","        num_heads=4,\n","        n_classes=1,\n","        n_posts=10,\n","        transaction_seq=108,\n","        transaction_features=11\n","        ):\n","        super(PonziShield, self).__init__()\n","\n","        self.multi_attn_flag = multi_attn_flag\n","        self.multiattn = MultiAttnModel(device, num_layers, model_dim, num_heads, hidden_dim, dropout)\n","        self.fc = nn.Linear(model_dim * 3, model_dim).to(device=device)\n","        self.mlp = MLP(device, model_dim, model_dim, n_classes, dropout)\n","        self.post_fusion_socialmedia = nn.Linear(n_posts * tensorfusion_out, model_dim).to(device=device)\n","        self.pre_fusion_transaction = nn.Linear(transaction_features, model_dim).to(device=device)\n","        self.post_fusion_transaction = nn.Linear(transaction_seq * model_dim, model_dim).to(device=device)\n","\n","        self.socialmedia_modality = SocialMediaModality(\n","            device,\n","            inductor,\n","            roberta_model_path,\n","            socialmedia_out,\n","            post_fusion_dim,\n","            post_fusion_dropout,\n","            embedding_dir\n","        )\n","\n","        self.transaction_modality = TransactionModality(device='cpu')\n","\n","        self.smartcode_modality = SocialMediaModality(\n","            device,\n","            inductor,\n","            roberta_model_path,\n","            socialmedia_out,\n","            post_fusion_dim,\n","            post_fusion_dropout,\n","            embedding_dir\n","        )\n","\n","    def forward(self, dapp_addresses, iteration, train, mode):\n","        sentiment_features = self.socialmedia_modality(dapp_addresses, iteration, train, mode)\n","        print('sentiment_features', sentiment_features.shape)\n","        contract_features = self.smartcode_modality(dapp_addresses, iteration, train, mode)\n","        print('contract_features', contract_features.shape)\n","        _, transaction_features = self.transaction_modality(dapp_addresses, train=True)\n","        # TODO\n","        transaction_features = transaction_features.to(device=device)\n","        print('transaction_features', transaction_features.shape)\n","        transaction_features = self.pre_fusion_transaction(transaction_features)\n","        print('transaction_features', transaction_features.shape)\n","\n","\n","        if self.multi_attn_flag == True:\n","            fused_sentiment_features, fused_contract_features, fused_transaction_features = self.multiattn(sentiment_features, contract_features, transaction_features)\n","        else:\n","            fused_sentiment_features, fused_contract_features, fused_transaction_features = sentiment_features, contract_features, transaction_features\n","\n","        print('fused_sentiment_features', fused_sentiment_features.shape)\n","        print('fused_contract_features', fused_contract_features.shape)\n","        print('fused_transaction_features', fused_transaction_features.shape)\n","\n","        fused_sentiment_features = fused_sentiment_features.reshape(fused_sentiment_features.shape[0], -1)\n","        fused_sentiment_features = self.post_fusion_socialmedia(fused_sentiment_features)\n","        fused_contract_features = fused_contract_features.reshape(fused_contract_features.shape[0], -1)\n","        fused_contract_features = self.post_fusion_socialmedia(fused_contract_features)\n","        fused_transaction_features = fused_transaction_features.reshape(fused_transaction_features.shape[0], -1)\n","        fused_transaction_features = self.post_fusion_transaction(fused_transaction_features)\n","\n","        print('fused_sentiment_features', fused_sentiment_features.shape)\n","        print('fused_contract_features', fused_contract_features.shape)\n","        print('fused_transaction_features', fused_transaction_features.shape)\n","\n","        fused_features = torch.cat((fused_sentiment_features, fused_contract_features, fused_transaction_features), dim = -1)\n","        print('fused_features', fused_features.shape)\n","        fc_outputs = self.fc(fused_features)\n","        print('fc_outputs', fc_outputs.shape)\n","        mlp_outputs = self.mlp(fc_outputs)\n","        print('mlp_outputs', mlp_outputs.shape)\n","\n","        return fused_sentiment_features, fused_contract_features, fused_transaction_features, fc_outputs, mlp_outputs"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["659c9244b46f4f00b48fbcba619099d9","2f4b6389325d4ca6ac3d1433dd0f4646","540f79eaffc04334836d5b91f02555af","bcf1674a9b874035b176e9dee2a25209","a48d732a43e544718a231f579f7c00cd","1740c43919734b778d8aa2eae4cd5d19","6c99dc45de2c41ffb8c1e20289eccc0a","583c02f447d54657ae70d793e10cfdad","ebaa644759c0408c899b4ab8471a5d2a","953bf695171946b1936aa49b5b063df4","86f7d95cc9cd42b5aa5ef3bcdb1c9ffc","1d2415f7a9d34d4ab3a1b5c624f68538","92515581a420445fa4ea6bb94e7c2b12","63548b234d9d4007870430c05ef96e3d","3fe2afdcc7af45c385d812ee81c3d4af","42df8b3b951b43aebacadc93a93b07a0","3026a0ed9da14e19b24b96b9405b68e9","710d0cd0927e44228c911ff876fafe9e","f11bf02f338d492fafc8cd9dfc6c54e9","4db444729666474099f01607b1d7fe84","1c6f13c6975f45ac8f1544b265ab5765","76c21cf38f4a408f8bd71d3e7e35b9f5","ec98217245a24ab39179e6b5baea6815","7458e188db054469be080c422658fc23","f9bb1d6c69664ba597ff892c33f69a3c","4a2e336bc6fd4f2e99e9cd76d09ceb68","067ff2ee78914110bcbf973140cc2096","c3ab3c6de2384b9583215f45b2da11be","42f04476a1a14c0690bccac13679bf49","0abc4707f35a4e3faae27bb56c80af1d","f1c507066cdc4c9cb90ed9764268c9e9","6df5b425eee9466db27b3eb18d0e7377","231cb1eb372c49df9cba9136ab86023d","d501e902fe0b40b181e3c920de25de53","1bf732356d0044b9b8e1def5741e194d","6ea31bb2ee0c4131ab2307dd36e281e4","004d4d6d5b504b4a8b3cb7e74cf0a3da","c4ef958077064a549d34cac8b2eb808c","36e03936c65a405c8c75f9abb94b3505","33fc1b8af1034a7a8cfbb0de6a253b8e","5ae7cdd76bb2462289a70c43f9f0f1f7","dc830f46cab74646a92c6b3a2c110ba8","5a981d5b663f4fac8a22d2066d6e3d7b","d109e31f4fad481094c1f002235ef1a9","ef6f1562ea2e423599c17a195ea6eacb","4206fc1dcb6a408098a92cb9963b97e0","16fc0b42591a40d7984faecfbd87ca77","9256064dee3047f0bff8723bf2d66234","344610f7f1ac41d4a1efbf77418d677a","46ffd8bff2dc4bd8bf493d264a809aab","dd72fd9945ad4fd5b8ecf0bbf1266e4b","5888925a523647c6b93733d00a50546c","20a66bd5a9df4bb6b2d7279a907e2247","e93c77eb942d4b1da799e57b08712ade","367f682f578d4dd8862fda5410a85fb1"]},"executionInfo":{"elapsed":85410,"status":"ok","timestamp":1703937948243,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"58Ev8aRIChXo","outputId":"6c03dae9-f1bd-496b-80cf-9d436810c679"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"659c9244b46f4f00b48fbcba619099d9","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d2415f7a9d34d4ab3a1b5c624f68538","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec98217245a24ab39179e6b5baea6815","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d501e902fe0b40b181e3c920de25de53","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef6f1562ea2e423599c17a195ea6eacb","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","fused_text_features shape: torch.Size([20, 256])\n","fused_audio_features shape: torch.Size([20, 256])\n","fused_visual_features shape: torch.Size([20, 256])\n","fc_outputs shape: torch.Size([20, 256])\n","mlp_outputs shape: torch.Size([20, 1])\n"]}],"source":["# Initialize the model\n","ponzishield = PonziShield(\n","    device=device\n",")\n","\n","addresses_tensor = torch.randint(1000, 10000, size=(20, 1), dtype=torch.int32)\n","\n","fused_text_features, fused_audio_features, fused_visual_features, fc_outputs, mlp_outputs = ponzishield(addresses_tensor, 1, True, 'train')\n","\n","print(\"fused_text_features shape:\", fused_text_features.shape)\n","print(\"fused_audio_features shape:\", fused_audio_features.shape)\n","print(\"fused_visual_features shape:\", fused_visual_features.shape)\n","print(\"fc_outputs shape:\", fc_outputs.shape)\n","print(\"mlp_outputs shape:\", mlp_outputs.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703938004884,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"thXd242Knn4F","outputId":"cf2ae319-ea5f-4790-d9fb-dfed73e9ec11"},"outputs":[{"data":{"text/plain":["torch.Size([20, 1])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["addresses_tensor.shape"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16797,"status":"ok","timestamp":1703940911060,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"bmZOCYlioYoL","outputId":"375bfb01-17ea-4983-eb95-8642694ebc6e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","sentiment_features torch.Size([7, 10, 256])\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","using saved embeddings\n","contract_features torch.Size([7, 10, 256])\n","torch.Size([7, 108, 11])\n","torch.Size([7])\n","transaction_features torch.Size([7, 108, 11])\n","transaction_features torch.Size([7, 108, 256])\n","fused_sentiment_features torch.Size([7, 10, 256])\n","fused_contract_features torch.Size([7, 10, 256])\n","fused_transaction_features torch.Size([7, 108, 256])\n","fused_sentiment_features torch.Size([7, 256])\n","fused_contract_features torch.Size([7, 256])\n","fused_transaction_features torch.Size([7, 256])\n","fused_features torch.Size([7, 768])\n","fc_outputs torch.Size([7, 256])\n","mlp_outputs torch.Size([7, 1])\n","fused_text_features shape: torch.Size([7, 256])\n","fused_audio_features shape: torch.Size([7, 256])\n","fused_visual_features shape: torch.Size([7, 256])\n","fc_outputs shape: torch.Size([7, 256])\n","mlp_outputs shape: torch.Size([7, 1])\n"]}],"source":["# Initialize the model\n","ponzishield = PonziShield(\n","    device=device\n",")\n","\n","contract_addresses = [\n","    \"0x6e38a457c722c6011b2dfa06d49240e797844d66\",\n","    \"0x109c4f2ccc82c4d77bde15f306707320294aea3f\",\n","    \"0x793ae8c1b1a160bfc07bfb0d04f85eab1a71f4f2\",\n","    \"0x5fe5b7546d1628f7348b023a0393de1fc825a4fd\",\n","    \"0xd79b4c6791784184e2755b2fc1659eaab0f80456\",\n","    \"0x273930d21e01ee25e4c219b63259d214872220a2\",\n","    \"0xd07ce4329b27eb8896c51458468d98a0e4c0394c\"\n","]\n","\n","fused_text_features, fused_audio_features, fused_visual_features, fc_outputs, mlp_outputs = ponzishield(contract_addresses, 1, True, 'train')\n","\n","print(\"fused_text_features shape:\", fused_text_features.shape)\n","print(\"fused_audio_features shape:\", fused_audio_features.shape)\n","print(\"fused_visual_features shape:\", fused_visual_features.shape)\n","print(\"fc_outputs shape:\", fc_outputs.shape)\n","print(\"mlp_outputs shape:\", mlp_outputs.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uqRP0fTIH37n"},"outputs":[],"source":["# del ponzishield\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"KZbMmDbbytq8"},"source":["#### Transaction model"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":794,"status":"ok","timestamp":1703938638341,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"5mAZZ57Z3Rg0"},"outputs":[],"source":["import torch\n","from torch import nn, Tensor\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","import math\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24228,"status":"ok","timestamp":1703937781328,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"gd4AHVpkb96C","outputId":"b613f8ba-3633-43fd-8e71-010298f54631"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1703938641144,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"K5sk_YF9EVBv"},"outputs":[],"source":["class BinaryClassification(nn.Module):\n","  def __init__(self, embed_size, device):\n","    super(BinaryClassification, self).__init__()\n","    # Number of input features is embed_size.\n","    self.layer_1 = nn.Linear(embed_size, 64)\n","    self.layer_2 = nn.Linear(64, 64)\n","    self.layer_out = nn.Linear(64, 1)\n","\n","    self.relu = nn.ReLU()\n","    self.dropout = nn.Dropout(p=0.1)\n","    self.batchnorm1 = nn.BatchNorm1d(64)\n","    self.batchnorm2 = nn.BatchNorm1d(64)\n","    self.device = device\n","\n","  def forward(self, inputs):\n","    # print(\"start binary classification\")\n","    # print(inputs.shape)\n","    # print(inputs)\n","    x = self.relu(self.layer_1(inputs))\n","    x = self.batchnorm1(x)\n","    x = self.relu(self.layer_2(x))\n","    x = self.batchnorm2(x)\n","    x = self.dropout(x)\n","    x = self.layer_out(x)\n","    #if math.isnan (x[0][0]):\n","    #  print(src)\n","\n","    return x"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":472,"status":"ok","timestamp":1703938643305,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"ki0ocBTRETIR"},"outputs":[],"source":["class Classifier(nn.Module):\n","  def __init__(self, d_model, seq_len, nhead, dim_feedforward, nlayers, device, dropout = 0.5):\n","    super(Classifier, self).__init__()\n","    self.d_model = d_model\n","    self.seq_len = seq_len\n","    self.nhead = nhead\n","    self.dim_feedforward = dim_feedforward\n","    self.nlayers = nlayers\n","    self.device = device\n","\n","    self.position_embedding = nn.Embedding(seq_len, d_model)\n","    encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n","    self.encoder = TransformerEncoder(encoder_layer, nlayers)\n","    self.binary_classifier = BinaryClassification(seq_len*d_model, device)\n","\n","  def forward(self, src: Tensor) -> Tensor:\n","\n","    \"\"\"\n","    Args:\n","        src: Tensor, shape [seq_len, batch_size]\n","        src_mask: Tensor, shape [seq_len, seq_len]\n","    Returns:\n","        output Tensor of shape [seq_len, batch_size, ntoken]\n","    \"\"\"\n","    N, seq_length, embed_size = src.shape\n","    positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n","    src_ = src + self.position_embedding(positions)\n","    output1 = self.encoder(src_)\n","    # print(output1.shape)\n","    # print(output1)\n","    output = self.binary_classifier(torch.reshape(output1, (N, seq_length*embed_size)))\n","\n","    return output, output1"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1215,"status":"ok","timestamp":1703938650717,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"GLkebdHaywJZ","outputId":"4ac084c7-3b5c-4b2c-b1d2-7738763b77d1"},"outputs":[{"data":{"text/plain":["Classifier(\n","  (position_embedding): Embedding(108, 11)\n","  (encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-7): 8 x TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=11, out_features=11, bias=True)\n","        )\n","        (linear1): Linear(in_features=11, out_features=8, bias=True)\n","        (dropout): Dropout(p=0.5, inplace=False)\n","        (linear2): Linear(in_features=8, out_features=11, bias=True)\n","        (norm1): LayerNorm((11,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((11,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.5, inplace=False)\n","        (dropout2): Dropout(p=0.5, inplace=False)\n","      )\n","    )\n","  )\n","  (binary_classifier): BinaryClassification(\n","    (layer_1): Linear(in_features=1188, out_features=64, bias=True)\n","    (layer_2): Linear(in_features=64, out_features=64, bias=True)\n","    (layer_out): Linear(in_features=64, out_features=1, bias=True)\n","    (relu): ReLU()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n",")"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["loaded_model = torch.load('/content/drive/MyDrive/23_FYP_Realtime_Estimation_of_Trustworthiness_of_Decentralized_Applications/models/PonziShield_tr_v1.pth')\n","loaded_model.eval()"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":1710,"status":"ok","timestamp":1703938657137,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"4m8eafwXFct3"},"outputs":[],"source":["X_test = np.load(\"/content/drive/MyDrive/23_FYP_Realtime_Estimation_of_Trustworthiness_of_Decentralized_Applications/models/tr/X_test.npy\", allow_pickle=True)\n","y_test = np.load(\"/content/drive/MyDrive/23_FYP_Realtime_Estimation_of_Trustworthiness_of_Decentralized_Applications/models/tr/y_test.npy\", allow_pickle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703849721328,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"},"user_tz":-330},"id":"eSr-fb3JGIPO","outputId":"7f47eeeb-fdea-4d80-9d8b-9f5d14cd3056"},"outputs":[{"name":"stdout","output_type":"stream","text":["(31, 108, 11)\n","(31,)\n"]}],"source":["print(X_test.shape)\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":691,"status":"ok","timestamp":1703939318146,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"x4X3xNANW6Cf","outputId":"30e23f11-3602-43b1-81a3-23f7b069723a"},"outputs":[{"data":{"text/plain":["array([[-0.10294521, -0.11435686, -0.01381463, ..., -0.23786669,\n","        -0.31210669, -0.2284082 ],\n","       [-0.10294521, -0.11435686, -0.01381463, ..., -0.23786669,\n","        -0.31210669, -0.2284082 ],\n","       [-0.10294521, -0.11435686, -0.01381463, ..., -0.23786669,\n","        -0.31210669, -0.2284082 ],\n","       ...,\n","       [-0.10294521, -0.11435686, -0.01381463, ..., -0.23786669,\n","        -0.31210669, -0.2284082 ],\n","       [-0.10294521, -0.11435686, -0.01381463, ..., -0.23786669,\n","        -0.31210669, -0.2284082 ],\n","       [-0.10294521, -0.11435686, -0.01381463, ..., -0.23786669,\n","        -0.31210669, -0.2284082 ]])"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["X_test[0]"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1703939319733,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"UVHuS8G8GbSG"},"outputs":[],"source":["## test data\n","class TestData(Dataset):\n","\n","    def __init__(self, X_data, y_data):\n","        self.X_data = X_data\n","        self.y_data = y_data\n","\n","    def __getitem__(self, index):\n","        return self.X_data[index], self.y_data[index]\n","\n","    def __len__ (self):\n","        return len(self.X_data)\n","\n","\n","test_data = TestData(X_test, y_test)"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703939321197,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"FESt6obIGon2"},"outputs":[],"source":["test_loader = DataLoader(dataset=test_data, batch_size=1)"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":941,"status":"ok","timestamp":1703939509093,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"LUM3NEiOGgZH"},"outputs":[],"source":["y_pred = []\n","y_true = []\n","sigmoid = nn.Sigmoid()\n","\n","for X_batch, y_batch in test_loader:\n","        #print(\"w.requires_grad:\",X_batch.requires_grad)\n","        X_batch, y_batch = X_batch.to(\"cpu\"), y_batch.to(\"cpu\")\n","        results,result_before_bin_classifier = loaded_model(X_batch.float())\n","        y_batch_pred = torch.round(sigmoid(results))\n","        y_pred.extend(y_batch_pred.cpu().detach().numpy())\n","        y_true.extend(y_batch.cpu().detach().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":338,"status":"ok","timestamp":1703845507991,"user":{"displayName":"Sandun Nishshanka","userId":"12516567792740475818"},"user_tz":-330},"id":"Z0SF3xWfGyb9","outputId":"eaef1f85-fbd6-4c32-a72f-8b0880dbc701"},"outputs":[{"name":"stdout","output_type":"stream","text":["31\n","0.7741935483870968\n"]}],"source":["count_true = 0\n","for i in range(len(y_pred)):\n","  if y_true[i]==y_pred[i]:\n","    count_true+=1\n","acc = count_true/len(y_pred)\n","print(len(y_test))\n","print(acc)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":478,"status":"ok","timestamp":1703938669064,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"dCv4ghFsYzuW"},"outputs":[],"source":["def create_tensor_inputs(embedding_dir,contract_address):\n","    all_data = []\n","    all_labels = []\n","    for i in range(len(contract_address)):\n","\n","        # print(filtered_df.loc[i, \"address\"], filtered_df.loc[i, \"label\"])\n","        fileNameToRead = embedding_dir + str(contract_address[i]) + '.csv'\n","        data = pd.read_csv(fileNameToRead)\n","        # Extract the relevant data (assuming the label column is named 'label')\n","        features = data.iloc[:, :11].to_numpy()\n","        label = data['label'][1]\n","        # print(features[1], labels[1])\n","        all_data.append((features))\n","        all_labels.append(label)\n","        # print(\"-----------------------------------------------------------------------\")\n","    data_array = np.array(all_data)\n","    labels_array = np.array(all_labels)\n","\n","    # Reshape the array to (301*108, 11) for normalization\n","    reshaped_data = data_array.reshape((-1, 11))\n","    # Initialize the StandardScaler\n","    scaler = StandardScaler()\n","    # Fit the scaler on the reshaped data and transform it\n","    normalized_data = scaler.fit_transform(reshaped_data)\n","    # Reshape the normalized data back to the original shape\n","    normalized_data_array = normalized_data.reshape(data_array.shape)\n","\n","    data_tensor = torch.tensor(normalized_data_array, dtype=torch.float32)\n","    labels_tensor = torch.tensor(labels_array, dtype=torch.float32)\n","\n","    print(data_tensor.shape)\n","    print(labels_tensor.shape)\n","    return data_tensor, labels_tensor\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4479,"status":"ok","timestamp":1703938684743,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"d_BHvomAY3uc","outputId":"ec1cb952-1e1d-4711-c5fb-bfd98eb004e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([7, 108, 11])\n","torch.Size([7])\n"]},{"data":{"text/plain":["(tensor([[[-0.2207, -0.2227, -0.1379,  ..., -0.6683,  3.1237, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683,  1.1492, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683,  1.1492, -0.7103],\n","          ...,\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103]],\n"," \n","         [[ 3.1714,  3.1648,  1.7379,  ...,  1.3607,  3.1237,  1.4198],\n","          [ 5.2067,  5.1973,  0.0358,  ...,  1.6143,  1.1492,  1.4198],\n","          [ 2.8806,  2.8745,  0.1921,  ...,  1.1071,  1.1492,  1.4198],\n","          ...,\n","          [-0.2207, -0.2227, -0.1379,  ...,  1.1071, -0.8253,  1.4198],\n","          [-0.2207, -0.2227, -0.1379,  ...,  1.6143, -0.8253,  1.4198],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.1610, -0.8253,  1.2068]],\n"," \n","         [[-0.2207, -0.2227, -0.1379,  ...,  1.8679,  1.1492,  1.4198],\n","          [-0.2207, -0.2227, -0.1379,  ...,  1.8679,  1.1492,  1.4198],\n","          [-0.2207, -0.2227, -0.1379,  ...,  1.8679,  1.1492,  1.4198],\n","          ...,\n","          [-0.2207, -0.2227, -0.1379,  ...,  1.8679,  1.1492,  1.4198],\n","          [-0.2207, -0.2227, -0.1377,  ...,  1.8679,  1.1492,  1.4198],\n","          [ 0.3220,  1.4033, -0.1377,  ...,  1.8679,  1.1492,  1.4198]],\n"," \n","         ...,\n"," \n","         [[ 1.5884,  1.5840, 17.3180,  ...,  0.0926,  3.1237,  1.4198],\n","          [ 3.3975,  3.3906, -0.0337,  ...,  0.0926,  1.1492,  1.4198],\n","          [-0.2207, -0.2227, -0.1206,  ..., -0.1610,  1.1492,  1.4198],\n","          ...,\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103]],\n"," \n","         [[-0.2207, -0.2227, -0.1377,  ..., -0.4146,  3.1237, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.4146,  1.1492, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.4146,  1.1492, -0.7103],\n","          ...,\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103]],\n"," \n","         [[-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          ...,\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n","          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103]]]),\n"," tensor([0., 1., 0., 0., 0., 0., 0.]))"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["contract_addresses = [\n","    \"0x6e38a457c722c6011b2dfa06d49240e797844d66\",\n","    \"0x109c4f2ccc82c4d77bde15f306707320294aea3f\",\n","    \"0x793ae8c1b1a160bfc07bfb0d04f85eab1a71f4f2\",\n","    \"0x5fe5b7546d1628f7348b023a0393de1fc825a4fd\",\n","    \"0xd79b4c6791784184e2755b2fc1659eaab0f80456\",\n","    \"0x273930d21e01ee25e4c219b63259d214872220a2\",\n","    \"0xd07ce4329b27eb8896c51458468d98a0e4c0394c\"\n","]\n","create_tensor_inputs('/content/drive/MyDrive/23_FYP_Realtime_Estimation_of_Trustworthiness_of_Decentralized_Applications/models/tr/data_set/',contract_addresses)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":467,"status":"ok","timestamp":1703938690555,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"TXEb_M9ZlRqP"},"outputs":[],"source":["class TransactionModality(nn.Module):\n","    def __init__(\n","        self,\n","        device,\n","        inductor=True,\n","        embedding_dir='/content/drive/MyDrive/23_FYP_Realtime_Estimation_of_Trustworthiness_of_Decentralized_Applications/models/tr/data_set/',\n","        model_path='/content/drive/MyDrive/23_FYP_Realtime_Estimation_of_Trustworthiness_of_Decentralized_Applications/models/PonziShield_tr_v1.pth',\n","        ):\n","        super(TransactionModality, self).__init__()\n","\n","        self.device = device\n","        self.embedding_dir=embedding_dir\n","        self.model = torch.load(model_path)\n","\n","    def forward(self, dapp_addresses, train):\n","\n","        if train==False:\n","            # do realtime prediction\n","            return\n","\n","\n","        # create 3d tensor [dapp_count,sequence_length,features]\n","        data_tensor, labels_tensor= create_tensor_inputs(self.embedding_dir,dapp_addresses)\n","        data_tensor = data_tensor.to(self.device)\n","        results,result_before_bin_classifier = self.model(data_tensor.float())\n","\n","        # results shape = [dapp_count,1], result_before_bin_classifier = [dapp_count,sequence_length,features]\n","        return results,result_before_bin_classifier"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":683,"status":"ok","timestamp":1703939597138,"user":{"displayName":"Nimsara Fernando","userId":"05456346427770267598"},"user_tz":-330},"id":"aCUsy6aGqSKh","outputId":"93788406-46a6-4852-e758-1b48cb88f9d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([7, 108, 11])\n","torch.Size([7])\n"]},{"data":{"text/plain":["torch.Size([7, 108, 11])"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["transactionModality = TransactionModality(device='cpu')\n","_, outputs_t = transactionModality(contract_addresses, train=True)\n","outputs_t.shape"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["CWNnsoKsAUlx","fLczmrg3yiYX"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"004d4d6d5b504b4a8b3cb7e74cf0a3da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a981d5b663f4fac8a22d2066d6e3d7b","placeholder":"","style":"IPY_MODEL_d109e31f4fad481094c1f002235ef1a9","value":" 456k/456k [00:00&lt;00:00, 3.44MB/s]"}},"067ff2ee78914110bcbf973140cc2096":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0abc4707f35a4e3faae27bb56c80af1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16fc0b42591a40d7984faecfbd87ca77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5888925a523647c6b93733d00a50546c","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20a66bd5a9df4bb6b2d7279a907e2247","value":1355863}},"1740c43919734b778d8aa2eae4cd5d19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bf732356d0044b9b8e1def5741e194d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36e03936c65a405c8c75f9abb94b3505","placeholder":"","style":"IPY_MODEL_33fc1b8af1034a7a8cfbb0de6a253b8e","value":"merges.txt: 100%"}},"1c6f13c6975f45ac8f1544b265ab5765":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d2415f7a9d34d4ab3a1b5c624f68538":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92515581a420445fa4ea6bb94e7c2b12","IPY_MODEL_63548b234d9d4007870430c05ef96e3d","IPY_MODEL_3fe2afdcc7af45c385d812ee81c3d4af"],"layout":"IPY_MODEL_42df8b3b951b43aebacadc93a93b07a0"}},"20a66bd5a9df4bb6b2d7279a907e2247":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"231cb1eb372c49df9cba9136ab86023d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f4b6389325d4ca6ac3d1433dd0f4646":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1740c43919734b778d8aa2eae4cd5d19","placeholder":"","style":"IPY_MODEL_6c99dc45de2c41ffb8c1e20289eccc0a","value":"config.json: 100%"}},"3026a0ed9da14e19b24b96b9405b68e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33fc1b8af1034a7a8cfbb0de6a253b8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"344610f7f1ac41d4a1efbf77418d677a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"367f682f578d4dd8862fda5410a85fb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36e03936c65a405c8c75f9abb94b3505":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fe2afdcc7af45c385d812ee81c3d4af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c6f13c6975f45ac8f1544b265ab5765","placeholder":"","style":"IPY_MODEL_76c21cf38f4a408f8bd71d3e7e35b9f5","value":" 499M/499M [00:02&lt;00:00, 218MB/s]"}},"4206fc1dcb6a408098a92cb9963b97e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46ffd8bff2dc4bd8bf493d264a809aab","placeholder":"","style":"IPY_MODEL_dd72fd9945ad4fd5b8ecf0bbf1266e4b","value":"tokenizer.json: 100%"}},"42df8b3b951b43aebacadc93a93b07a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42f04476a1a14c0690bccac13679bf49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46ffd8bff2dc4bd8bf493d264a809aab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a2e336bc6fd4f2e99e9cd76d09ceb68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6df5b425eee9466db27b3eb18d0e7377","placeholder":"","style":"IPY_MODEL_231cb1eb372c49df9cba9136ab86023d","value":" 899k/899k [00:00&lt;00:00, 4.53MB/s]"}},"4db444729666474099f01607b1d7fe84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"540f79eaffc04334836d5b91f02555af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_583c02f447d54657ae70d793e10cfdad","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebaa644759c0408c899b4ab8471a5d2a","value":481}},"583c02f447d54657ae70d793e10cfdad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5888925a523647c6b93733d00a50546c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a981d5b663f4fac8a22d2066d6e3d7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ae7cdd76bb2462289a70c43f9f0f1f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63548b234d9d4007870430c05ef96e3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f11bf02f338d492fafc8cd9dfc6c54e9","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4db444729666474099f01607b1d7fe84","value":498818054}},"659c9244b46f4f00b48fbcba619099d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f4b6389325d4ca6ac3d1433dd0f4646","IPY_MODEL_540f79eaffc04334836d5b91f02555af","IPY_MODEL_bcf1674a9b874035b176e9dee2a25209"],"layout":"IPY_MODEL_a48d732a43e544718a231f579f7c00cd"}},"6c99dc45de2c41ffb8c1e20289eccc0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6df5b425eee9466db27b3eb18d0e7377":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ea31bb2ee0c4131ab2307dd36e281e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ae7cdd76bb2462289a70c43f9f0f1f7","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc830f46cab74646a92c6b3a2c110ba8","value":456318}},"710d0cd0927e44228c911ff876fafe9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7458e188db054469be080c422658fc23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3ab3c6de2384b9583215f45b2da11be","placeholder":"","style":"IPY_MODEL_42f04476a1a14c0690bccac13679bf49","value":"vocab.json: 100%"}},"76c21cf38f4a408f8bd71d3e7e35b9f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86f7d95cc9cd42b5aa5ef3bcdb1c9ffc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92515581a420445fa4ea6bb94e7c2b12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3026a0ed9da14e19b24b96b9405b68e9","placeholder":"","style":"IPY_MODEL_710d0cd0927e44228c911ff876fafe9e","value":"model.safetensors: 100%"}},"9256064dee3047f0bff8723bf2d66234":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e93c77eb942d4b1da799e57b08712ade","placeholder":"","style":"IPY_MODEL_367f682f578d4dd8862fda5410a85fb1","value":" 1.36M/1.36M [00:00&lt;00:00, 5.20MB/s]"}},"953bf695171946b1936aa49b5b063df4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a48d732a43e544718a231f579f7c00cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcf1674a9b874035b176e9dee2a25209":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_953bf695171946b1936aa49b5b063df4","placeholder":"","style":"IPY_MODEL_86f7d95cc9cd42b5aa5ef3bcdb1c9ffc","value":" 481/481 [00:00&lt;00:00, 31.0kB/s]"}},"c3ab3c6de2384b9583215f45b2da11be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ef958077064a549d34cac8b2eb808c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d109e31f4fad481094c1f002235ef1a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d501e902fe0b40b181e3c920de25de53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bf732356d0044b9b8e1def5741e194d","IPY_MODEL_6ea31bb2ee0c4131ab2307dd36e281e4","IPY_MODEL_004d4d6d5b504b4a8b3cb7e74cf0a3da"],"layout":"IPY_MODEL_c4ef958077064a549d34cac8b2eb808c"}},"dc830f46cab74646a92c6b3a2c110ba8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd72fd9945ad4fd5b8ecf0bbf1266e4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e93c77eb942d4b1da799e57b08712ade":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebaa644759c0408c899b4ab8471a5d2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec98217245a24ab39179e6b5baea6815":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7458e188db054469be080c422658fc23","IPY_MODEL_f9bb1d6c69664ba597ff892c33f69a3c","IPY_MODEL_4a2e336bc6fd4f2e99e9cd76d09ceb68"],"layout":"IPY_MODEL_067ff2ee78914110bcbf973140cc2096"}},"ef6f1562ea2e423599c17a195ea6eacb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4206fc1dcb6a408098a92cb9963b97e0","IPY_MODEL_16fc0b42591a40d7984faecfbd87ca77","IPY_MODEL_9256064dee3047f0bff8723bf2d66234"],"layout":"IPY_MODEL_344610f7f1ac41d4a1efbf77418d677a"}},"f11bf02f338d492fafc8cd9dfc6c54e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c507066cdc4c9cb90ed9764268c9e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9bb1d6c69664ba597ff892c33f69a3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0abc4707f35a4e3faae27bb56c80af1d","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1c507066cdc4c9cb90ed9764268c9e9","value":898823}}}}},"nbformat":4,"nbformat_minor":0}
